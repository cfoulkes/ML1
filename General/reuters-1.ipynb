{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e244e374f8917213bc4203480a0c9ac20d05215c162c3a1373ddaab3b7be7571"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8982\n2246\n[1, 361, 372, 8, 77, 62, 325, 4105, 336, 5, 1605, 37, 412, 453, 1187, 229, 334, 13, 4, 867, 76, 4, 76, 1726, 6, 264, 2337, 18, 82, 95, 97, 2220, 4, 1004, 649, 18, 82, 554, 136, 4, 143, 334, 290, 126, 5, 4, 2820, 777, 2, 1386, 13, 954, 7, 4, 314, 912, 224, 4, 2370, 1128, 54, 429, 2, 18, 82, 5, 496, 1187, 229, 57, 85, 385, 593, 6, 4, 867, 76, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(test_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n3\n"
     ]
    }
   ],
   "source": [
    "# decode\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "decoded = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "\n",
    "print(decoded)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "print(one_hot_train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# or using Keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(one_hot_train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set aside validation set\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s 526us/step - loss: 2.7090 - accuracy: 0.4678 - val_loss: 1.7525 - val_accuracy: 0.6500\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 283us/step - loss: 1.4284 - accuracy: 0.7068 - val_loss: 1.3049 - val_accuracy: 0.7150\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 191us/step - loss: 1.0528 - accuracy: 0.7762 - val_loss: 1.1280 - val_accuracy: 0.7560\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.8372 - accuracy: 0.8201 - val_loss: 1.0356 - val_accuracy: 0.7710\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 287us/step - loss: 0.6684 - accuracy: 0.8583 - val_loss: 1.0284 - val_accuracy: 0.7760\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 303us/step - loss: 0.5382 - accuracy: 0.8875 - val_loss: 0.9249 - val_accuracy: 0.8050\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 307us/step - loss: 0.4289 - accuracy: 0.9102 - val_loss: 0.8888 - val_accuracy: 0.8110\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 213us/step - loss: 0.3513 - accuracy: 0.9261 - val_loss: 0.8744 - val_accuracy: 0.8230\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 0.2909 - accuracy: 0.9351 - val_loss: 0.9012 - val_accuracy: 0.8190\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 290us/step - loss: 0.2459 - accuracy: 0.9436 - val_loss: 0.8902 - val_accuracy: 0.8290\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 4s 504us/step - loss: 0.2137 - accuracy: 0.9481 - val_loss: 0.8899 - val_accuracy: 0.8280\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s 344us/step - loss: 0.1853 - accuracy: 0.9525 - val_loss: 0.9416 - val_accuracy: 0.8190\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 275us/step - loss: 0.1694 - accuracy: 0.9501 - val_loss: 1.0013 - val_accuracy: 0.8080\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.1568 - accuracy: 0.9534 - val_loss: 0.9548 - val_accuracy: 0.8160\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s 334us/step - loss: 0.1371 - accuracy: 0.9570 - val_loss: 1.0141 - val_accuracy: 0.8100\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 4s 484us/step - loss: 0.1312 - accuracy: 0.9572 - val_loss: 0.9963 - val_accuracy: 0.8230\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 306us/step - loss: 0.1334 - accuracy: 0.9543 - val_loss: 1.0654 - val_accuracy: 0.8090\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.1203 - accuracy: 0.9580 - val_loss: 1.0563 - val_accuracy: 0.8040\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 0.1153 - accuracy: 0.9579 - val_loss: 1.0658 - val_accuracy: 0.8050\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 196us/step - loss: 0.1123 - accuracy: 0.9574 - val_loss: 1.0948 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# plot training and validation results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}